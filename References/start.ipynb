{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "start.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Sy4a2I0GEhU",
        "outputId": "b4041bec-0092-4984-af13-f5bc19975914"
      },
      "source": [
        "%tensorflow_version 1.x\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yoe20NsAGTSP",
        "outputId": "1317d6f8-9599-47f6-be94-9d5a1d15414f"
      },
      "source": [
        "import tensorflow as tf\r\n",
        "from tensorflow import keras\r\n",
        "\r\n",
        "mnist = tf.keras.datasets.mnist\r\n",
        "\r\n",
        "(x_train, y_train),(x_test, y_test) = mnist.load_data()\r\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0\r\n",
        "\r\n",
        "x_train = x_train.reshape(x_train.shape[0], 28, 28, 1)\r\n",
        "x_test = x_test.reshape(x_test.shape[0], 28, 28, 1)\r\n",
        "\r\n",
        "model = tf.keras.models.Sequential([\r\n",
        "  tf.keras.layers.Conv2D(input_shape=(28, 28,1), filters=16, kernel_size=5, strides=2, padding='same'),\r\n",
        "  tf.keras.layers.BatchNormalization(),\r\n",
        "  tf.keras.layers.ReLU(),\r\n",
        "  tf.keras.layers.Conv2D(filters=32, kernel_size=5, strides=2, padding='same'),\r\n",
        "  tf.keras.layers.BatchNormalization(),\r\n",
        "  tf.keras.layers.ReLU(),\r\n",
        "  tf.keras.layers.Conv2D(filters=64, kernel_size=5, strides=2, padding='same'),\r\n",
        "  tf.keras.layers.BatchNormalization(),\r\n",
        "  tf.keras.layers.ReLU(),\r\n",
        "  #tf.keras.layers.Conv2D(filters=10, kernel_size=5, strides=2, padding='same'),\r\n",
        "  tf.keras.layers.Conv2D(filters=10, kernel_size=5, strides=4, padding='same'),\r\n",
        "  tf.keras.layers.BatchNormalization(),\r\n",
        "  tf.keras.layers.Activation(activation='sigmoid'),\r\n",
        "  #tf.keras.layers.ReLU(),\r\n",
        "  #tf.keras.layers.Dropout(0.2),\r\n",
        "  #tf.keras.layers.Dense(10, activation=tf.nn.softmax),\r\n",
        "  #tf.keras.layers.Dense(10),\r\n",
        "  tf.keras.layers.Flatten()\r\n",
        "])\r\n",
        "\r\n",
        "\"\"\"\r\n",
        "model = tf.keras.models.Sequential([\r\n",
        "  tf.keras.layers.Flatten(input_shape=(28, 28,1)),\r\n",
        "  tf.keras.layers.Dense(512, activation=tf.nn.relu),\r\n",
        "  tf.keras.layers.Dropout(0.2),\r\n",
        "  tf.keras.layers.Dense(10, activation=tf.nn.softmax),\r\n",
        "])\r\n",
        "\"\"\"\r\n",
        "model.compile(optimizer='adam',\r\n",
        "              loss='sparse_categorical_crossentropy',\r\n",
        "              metrics=['accuracy'])\r\n",
        "\r\n",
        "model.fit(x_train, y_train, epochs=1)\r\n",
        "model.evaluate(x_test, y_test)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "Train on 60000 samples\n",
            "60000/60000 [==============================] - 42s 697us/sample - loss: 1.0960 - acc: 0.9366\n",
            "10000/10000 [==============================] - 2s 236us/sample - loss: 0.5930 - acc: 0.9828\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.5930470597267151, 0.9828]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wv9TJvuiSuGc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9f7c9a3f-eabc-4ee9-b82d-daabb6c37e86"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 14, 14, 16)        416       \n",
            "_________________________________________________________________\n",
            "batch_normalization (BatchNo (None, 14, 14, 16)        64        \n",
            "_________________________________________________________________\n",
            "re_lu (ReLU)                 (None, 14, 14, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 7, 7, 32)          12832     \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 7, 7, 32)          128       \n",
            "_________________________________________________________________\n",
            "re_lu_1 (ReLU)               (None, 7, 7, 32)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 4, 4, 64)          51264     \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 4, 4, 64)          256       \n",
            "_________________________________________________________________\n",
            "re_lu_2 (ReLU)               (None, 4, 4, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 1, 1, 10)          16010     \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 1, 1, 10)          40        \n",
            "_________________________________________________________________\n",
            "activation (Activation)      (None, 1, 1, 10)          0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 81,010\n",
            "Trainable params: 80,766\n",
            "Non-trainable params: 244\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VGHr7fDiH9_c"
      },
      "source": [
        "# save weights, model architecture & optimizer to an HDF5 format file\r\n",
        "model.save('mnist.h5')"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YEYTi3dtHu8f"
      },
      "source": [
        "# fetch the tensorflow session using the Keras backend\r\n",
        "#tf_session = tf.keras.backend.get_session()\r\n",
        "\r\n",
        "# write out tensorflow checkpoint & meta graph\r\n",
        "#tf.saved_model.save(model, \"amit\")\r\n",
        "\r\n",
        "#saver = tf.compat.v1.train.Saver()\r\n",
        "#save_path = saver.save(tf_session,tf_ckpt)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EuM9XdhnrEJW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "outputId": "c1734e3f-23fb-44cb-e005-0bb834d35414"
      },
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "def freeze_session(session, keep_var_names=None, output_names=None, clear_devices=True):\n",
        "    \"\"\"\n",
        "    Freezes the state of a session into a pruned computation graph.\n",
        "â€‹\n",
        "    Creates a new computation graph where variable nodes are replaced by\n",
        "    constants taking their current value in the session. The new graph will be\n",
        "    pruned so subgraphs that are not necessary to compute the requested\n",
        "    outputs are removed.\n",
        "    @param session The TensorFlow session to be frozen.\n",
        "    @param keep_var_names A list of variable names that should not be frozen,\n",
        "                          or None to freeze all the variables in the graph.\n",
        "    @param output_names Names of the relevant graph outputs.\n",
        "    @param clear_devices Remove the device directives from the graph for better portability.\n",
        "    @return The frozen graph definition.\n",
        "    \"\"\"\n",
        "    graph = session.graph\n",
        "    with graph.as_default():\n",
        "        freeze_var_names = list(set(v.op.name for v in tf.global_variables()).difference(keep_var_names or []))\n",
        "        output_names = output_names or []\n",
        "        output_names += [v.op.name for v in tf.global_variables()]\n",
        "        input_graph_def = graph.as_graph_def()\n",
        "        if clear_devices:\n",
        "            for node in input_graph_def.node:\n",
        "                node.device = \"\"\n",
        "        frozen_graph = tf.graph_util.convert_variables_to_constants(\n",
        "            session, input_graph_def, output_names, freeze_var_names)\n",
        "    return frozen_graph\n",
        "\n",
        "keras.backend.set_learning_phase(0)\n",
        "loaded_model= keras.models.load_model('./mnist.h5')\n",
        "\n",
        "# make list of output and input node names\n",
        "input_names=[out.op.name for out in loaded_model.inputs]\n",
        "output_names=[out.op.name for out in loaded_model.outputs]\n",
        "print('input  node is{}'.format(input_names))\n",
        "print('output node is{}'.format(output_names))\n",
        "\n",
        "f = open(\"input_output_node_name.txt\", \"w+\")\n",
        "f.write('input  node is{}'.format(input_names) + \"\\n\")\n",
        "f.write('output node is{}'.format(output_names) + \"\\n\")\n",
        "f.close()\n",
        "\n",
        "frozen_graph = freeze_session(keras.backend.get_session(), output_names=output_names)\n",
        "\n",
        "tf.train.write_graph(frozen_graph, \"./\", \"frozen_graph.pb\", as_text=False)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/init_ops.py:97: calling GlorotUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/init_ops.py:97: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/init_ops.py:97: calling Ones.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "input  node is['conv2d_input_1']\n",
            "output node is['flatten_1/Reshape']\n",
            "WARNING:tensorflow:From <ipython-input-6-f1fd8315a075>:32: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.compat.v1.graph_util.convert_variables_to_constants`\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/framework/graph_util_impl.py:277: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.compat.v1.graph_util.extract_sub_graph`\n",
            "INFO:tensorflow:Froze 122 variables.\n",
            "INFO:tensorflow:Converted 122 variables to const ops.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'./frozen_graph.pb'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-gtGJLe9UtBY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "39f0c52d-5c60-425f-d2b3-861dacc58236"
      },
      "source": [
        "\"\"\"\n",
        "#saver = tf.train.Saver()\n",
        "# session is run\n",
        "sess = tf.Session()\n",
        "#initialize the variables\n",
        "sess.run(tf.global_variables_initializer())\n",
        "# save the variables\n",
        "saver.save(sess, './simple_model')\n",
        "# saving the graph using tf.io.write_graph\n",
        "tf.io.write_graph(sess.graph, './graph', 'graph.pbtxt')\n",
        "\"\"\""
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"\\n#saver = tf.train.Saver()\\n# session is run\\nsess = tf.Session()\\n#initialize the variables\\nsess.run(tf.global_variables_initializer())\\n# save the variables\\nsaver.save(sess, './simple_model')\\n# saving the graph using tf.io.write_graph\\ntf.io.write_graph(sess.graph, './graph', 'graph.pbtxt')\\n\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yFL0Nj1tVzfw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "58c76366-93b0-4e70-fe01-f46d7f625ec3"
      },
      "source": [
        "\"\"\"\n",
        "import tensorflow as tf\n",
        "from tensorflow.python.framework import graph_util\n",
        "\n",
        "saver = tf.train.import_meta_graph('./simple_model.meta')\n",
        "graph = tf.get_default_graph()\n",
        "input_graph_def = graph.as_graph_def()\n",
        "#sess = tf.Session()\n",
        "\n",
        "session = keras.backend.get_session()\n",
        "init = tf.global_variables_initializer()\n",
        "session.run(init)\n",
        "\n",
        "saver.restore(sess, \"./simple_model\")\n",
        "\n",
        "# this will be seen from the file graph.pbtxt\n",
        "output_node_names=\"init\"\n",
        "output_graph_def = graph_util.convert_variables_to_constants(\n",
        "            session,\n",
        "            input_graph_def,  \n",
        "            output_node_names.split(\",\")\n",
        "            )  \n",
        "\n",
        "\n",
        "output_graph= \"./simple_model .pb\"\n",
        "print(\"output_graph...\", output_graph)\n",
        "\n",
        "with tf.gfile.GFile(output_graph, \"wb\") as f:\n",
        "    f.write(output_graph_def.SerializeToString())\n",
        "\n",
        "# closing the session\n",
        "sess.close()\n",
        "\"\"\""
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\nimport tensorflow as tf\\nfrom tensorflow.python.framework import graph_util\\n\\nsaver = tf.train.import_meta_graph(\\'./simple_model.meta\\')\\ngraph = tf.get_default_graph()\\ninput_graph_def = graph.as_graph_def()\\n#sess = tf.Session()\\n\\nsession = keras.backend.get_session()\\ninit = tf.global_variables_initializer()\\nsession.run(init)\\n\\nsaver.restore(sess, \"./simple_model\")\\n\\n# this will be seen from the file graph.pbtxt\\noutput_node_names=\"init\"\\noutput_graph_def = graph_util.convert_variables_to_constants(\\n            session,\\n            input_graph_def,  \\n            output_node_names.split(\",\")\\n            )  \\n\\n\\noutput_graph= \"./simple_model .pb\"\\nprint(\"output_graph...\", output_graph)\\n\\nwith tf.gfile.GFile(output_graph, \"wb\") as f:\\n    f.write(output_graph_def.SerializeToString())\\n\\n# closing the session\\nsess.close()\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WuUO9oUsaWva"
      },
      "source": [
        "#[node.name for node in model.inputs]"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ylHBlx_WaecG"
      },
      "source": [
        "#[node.name for node in model.outputs]"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5-9X7U-Pl6ci"
      },
      "source": [
        ""
      ],
      "execution_count": 10,
      "outputs": []
    }
  ]
}